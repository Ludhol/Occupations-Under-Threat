{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitd863a529c1fa4d128753e3d722b9a701",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import datetime as dt\n",
    "import community\n",
    "from shapely.geometry import Polygon\n",
    "import importlib\n",
    "\n",
    "import DDOM # Data Driven Occupational Mobility\n",
    "import model_cal\n",
    "importlib.reload(DDOM)\n",
    "import random\n",
    "import math\n",
    "\n",
    "import simpy\n",
    "\n",
    "import cmocean as cmo\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from data_processing.ipynb\n",
    "sa_calibration_data = pd.read_csv('../Data_Labour/calibration_data.csv')\n",
    "employment_SSYK = pd.read_csv('../Data_Labour/occupational_employment.csv', sep = ',')\n",
    "SSYK_shock = pd.read_csv('../Data_Labour/occupation_shock.csv', sep = ',')\n",
    "\n",
    "G = nx.read_graphml('../Data_Labour/Occ_mob_sweden.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_simulation(individual, G, period, timestep, empirical_data, k, L, avg_hours_0, shock_start, attributes, calibration_output = False):\n",
    "    #set_attributes(G, data)\n",
    "    # This needs to be put into the network (used as starting point)\n",
    "\n",
    "    for key, value in attributes.items():\n",
    "        nx.set_node_attributes(G, value, str(key))\n",
    "\n",
    "    timesteps = round(period*52/timestep)*3 # Total amount of steps\n",
    "    T_steps = round(period*52/timestep) # Steps during simulated business cycle\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    vacancies = nx.get_node_attributes(G, 'vacancies')\n",
    "    employed = nx.get_node_attributes(G, 'employed')\n",
    "\n",
    "    demand_0 = {}\n",
    "\n",
    "    for key in vacancies.keys():\n",
    "        demand_0[key] = vacancies[key] + employed[key] \n",
    "\n",
    "    vac_data = []\n",
    "    emp_data = []\n",
    "    unemp_data = []\n",
    "    td_data = []\n",
    "\n",
    "    # Variables to calculate the post shock demand\n",
    "    risk_factor = nx.get_node_attributes(G, 'comp_prob')\n",
    "    average_hours_worked_0 = avg_hours_0\n",
    "    \n",
    "\n",
    "    final_hours_worked = {}\n",
    "\n",
    "    for occupation in risk_factor.keys():\n",
    "        final_hours_worked[occupation] = average_hours_worked_0*employed[occupation]*(1-risk_factor[occupation])\n",
    "\n",
    "    final_average_hours_worked = sum(final_hours_worked.values())/L\n",
    "\n",
    "    # Post shock demand\n",
    "    final_demand = {occupation:hours/final_average_hours_worked for occupation, hours in final_hours_worked.items()}\n",
    "\n",
    "    occupations = list(G.nodes())\n",
    "    time = dt.datetime.now()\n",
    "\n",
    "    a = individual[0]\n",
    "    delta_u = individual[1]\n",
    "    delta_ny = individual[2]\n",
    "    gamma_u = individual[3]\n",
    "\n",
    "    print('Simulation started at: ', time)\n",
    "    for t in range(timesteps):\n",
    "        ny = nx.get_node_attributes(G, 'vacancies')\n",
    "        u = nx.get_node_attributes(G, 'unemployed')\n",
    "        e = nx.get_node_attributes(G, 'employed')\n",
    "        A = nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "        s = {}\n",
    "        f = {}\n",
    "        for j in occupations:\n",
    "            s[j] = []\n",
    "            for i in G.predecessors(j):\n",
    "                ny_A_sum = sum([ny[k]*A[(i,k)] for k in G.neighbors(i)])\n",
    "                if ny_A_sum == 0:\n",
    "                    s[j].append(0)\n",
    "                else:\n",
    "                    s[j].append(u[i]*ny[j]*A[(i,j)]/ny_A_sum)\n",
    "\n",
    "            s[j] = sum(s[j])\n",
    "            for i in G.predecessors(j):\n",
    "                ny_A_sum = sum([ny[k]*A[(i,k)] for k in G.neighbors(i)])\n",
    "                if s[j]*ny_A_sum == 0:\n",
    "                    f[(i,j)] = 0\n",
    "                else:\n",
    "                    f[(i,j)] = u[i]*(ny[j]**(2))*A[(i,j)]*(1 - math.exp(-s[j]/ny[j]))/(s[j]*ny_A_sum)\n",
    "\n",
    "        new_e = {}\n",
    "        new_u = {}\n",
    "        new_ny = {}\n",
    "        \n",
    "        target_demand = nx.get_node_attributes(G, 'target_demand')\n",
    "        current_demand = {}\n",
    "\n",
    "        for i in occupations:\n",
    "            current_demand[i] = ny[i] + e[i]\n",
    "            demand_diff = max(0, current_demand[i] - target_demand[i])\n",
    "\n",
    "            f_i = sum([f[(j,i)] for j in G.predecessors(i)])\n",
    "\n",
    "            new_e[i] = e[i] - delta_u*e[i] + (1 - delta_u)*gamma_u*demand_diff + f_i\n",
    "\n",
    "            f_j = sum([f[(i,j)] for j in G.successors(i)])\n",
    "\n",
    "            new_u[i] = u[i] + delta_u*e[i] + (1 - delta_u)*gamma_u*demand_diff - f_j\n",
    "\n",
    "            demand_diff = max(0, target_demand[i]-current_demand[i])\n",
    "\n",
    "            new_ny[i] = ny[i] + delta_ny*e[i] + (1-delta_ny)*gamma_u*demand_diff - f_i\n",
    "\n",
    "        nx.set_node_attributes(G, new_ny, 'vacancies')\n",
    "        nx.set_node_attributes(G, new_e, 'employed')\n",
    "        nx.set_node_attributes(G, new_u, 'unemployed')\n",
    "\n",
    "        vac_data.append(nx.get_node_attributes(G, 'vacancies'))\n",
    "        unemp_data.append(nx.get_node_attributes(G, 'unemployed'))\n",
    "        emp_data.append(nx.get_node_attributes(G, 'employed'))\n",
    "        td_data.append(target_demand)\n",
    "\n",
    "        if T_steps < t:\n",
    "            DDOM.update_target_demand(G, demand_0, t, T_steps, a)\n",
    "        # order should be checked and changed\n",
    "        # if t > shock_start:\n",
    "        #    shock(G, demand_0, final_demand, t, t_0, k)\n",
    "\n",
    "    model_data = {'vacancies': vac_data, 'unemployment': unemp_data, 'employment':emp_data}\n",
    "    # Empirical data\n",
    "    e_vac_rate = empirical_data['sa_vac_rate']\n",
    "    e_unemployed = empirical_data['u_trend']\n",
    "    e_seq = [(u, e_vac_rate.iloc[i]) for i, u in enumerate(e_unemployed)]#\n",
    "    e_u_max = max(e_unemployed)\n",
    "    e_u_min = min(e_unemployed)\n",
    "    e_vac_max = max(e_vac_rate)\n",
    "    e_vac_min = min(e_vac_rate)\n",
    "\n",
    "    \n",
    "\n",
    "    A_e = Polygon(e_seq).buffer(0)\n",
    "\n",
    "    # Cost is a vector of deviations from goal. Should be 0\n",
    "    cost = DDOM.calibration_calculation(empirical_data, model_data, A_e, T_steps)\n",
    "\n",
    "    # m_td = [sum(demand.values()) for demand in td_data]\n",
    "    # plt.plot(m_td)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    cost['A_e'] = A_e.area\n",
    "    # if cost['intersection'] != 'N/A' and cost['union'] != 'N/A' and cost['A_m'] != 'N/A':\n",
    "    #     fitness = [\n",
    "    #         abs(cost['A_e']-cost['A_m']),\n",
    "    #         abs(e_u_max - cost['m_u_max']),\n",
    "    #         abs(e_u_min - cost['m_u_min']),\n",
    "    #         abs(e_vac_max - cost['m_vac_max']),\n",
    "    #         abs(e_vac_min - cost['m_vac_min']),\n",
    "    #         abs(cost['A_e'] - cost['intersection']),\n",
    "    #         abs(cost['A_e'] - cost['union']),\n",
    "    #         cost['union'] - cost['intersection']\n",
    "    #     ]\n",
    "    # elif cost['A_m'] != 'N/A':\n",
    "    #     fitness = [\n",
    "    #         abs(cost['A_e']-cost['A_m']),\n",
    "    #         abs(e_u_max - cost['m_u_max']),\n",
    "    #         abs(e_u_min - cost['m_u_min']),\n",
    "    #         abs(e_vac_max - cost['m_vac_max']),\n",
    "    #         abs(e_vac_min - cost['m_vac_min'])\n",
    "    #     ]\n",
    "    # else:\n",
    "    #     fitness = [\n",
    "    #         abs(e_u_max - cost['m_u_max']),\n",
    "    #         abs(e_u_min - cost['m_u_min']),\n",
    "    #         abs(e_vac_max - cost['m_vac_max']),\n",
    "    #         abs(e_vac_min - cost['m_vac_min'])\n",
    "    #     ]\n",
    "    fitness = [\n",
    "    abs(e_u_max - cost['m_u_max']),\n",
    "    abs(e_u_min - cost['m_u_min']),\n",
    "    abs(e_vac_max - cost['m_vac_max']),\n",
    "    abs(e_vac_min - cost['m_vac_min'])\n",
    "    ]\n",
    "    fitness = np.linalg.norm(fitness)\n",
    "\n",
    "    vac_data = pd.DataFrame(vac_data)\n",
    "    unemp_data = pd.DataFrame(unemp_data)\n",
    "    emp_data = pd.DataFrame(emp_data)\n",
    "    time = dt.datetime.now()- time\n",
    "    print('Simulation took: ', time)\n",
    "    cost['time'] = time\n",
    "    if calibration_output == 'evo':\n",
    "        return fitness\n",
    "    elif calibration_output == 'True':\n",
    "        return cost\n",
    "    else:\n",
    "        return {'vacancy_data': vac_data, 'unemployment_data': unemp_data, 'employment_data': emp_data, 'cost': cost}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(individual):\n",
    "    while individual[1] < individual[2]:\n",
    "        individual[1] += 0.01\n",
    "    employment = employment_SSYK[['SSYK', '2014']]\n",
    "    employment = {str(employment['SSYK'].iloc[i]):employment['2014'].iloc[i] for i in range(len(employment))}\n",
    "    node_names = list(G.nodes())\n",
    "\n",
    "    # setup network\n",
    "    employed = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "    unemployed = {name:0 for name in node_names}\n",
    "    vacancies = {name:0 for name in node_names}\n",
    "    applications = {name:[] for name in node_names}\n",
    "    target_demand = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "    of_data = SSYK_shock.groupby(by = ['ssyk3'], axis = 0).mean()\n",
    "    of_data = of_data.to_dict()['Computerisation Probability']\n",
    "    attributes = {'employed':employed, 'unemployed':unemployed, 'vacancies':vacancies, 'applications':applications,\n",
    "                    'target_demand':target_demand, 'comp_prob':of_data}\n",
    "\n",
    "    # Save parameters\n",
    "\n",
    "\n",
    "    # Calibration data\n",
    "    start = 18\n",
    "    end = 59\n",
    "    empirical_data = sa_calibration_data.iloc[start:end]\n",
    "    parameters = {}\n",
    "    \n",
    "    parameters['T'] = 15\n",
    "    # Shock parameters (not there yet)\n",
    "    parameters['t_0'] = 10\n",
    "    parameters['years'] = parameters['T'] + parameters['t_0']\n",
    "    parameters['k'] = 1\n",
    "    parameters['L'] = 1\n",
    "    parameters['avg_hours_0'] = 1\n",
    "    parameters['shock_start'] = 1\n",
    "    parameters['timestep'] = 6\n",
    "\n",
    "    calibration_output = 'evo'\n",
    "\n",
    "    # Run simulation\n",
    "    fitness = deterministic_simulation(individual, G, parameters['T'], parameters['timestep'], empirical_data,\n",
    "                    parameters['k'], parameters['L'], parameters['avg_hours_0'], parameters['shock_start'],\n",
    "                    attributes, calibration_output)\n",
    "    print('a:', individual[0], 'delta_u:', individual[1], 'delta_ny:', individual[2], 'gamma_u:', individual[3], 'fitness:', fitness)\n",
    "\n",
    "    string = 'a: ' + str(individual[0]) + ' delta_u: ' + str(individual[1]) + ' delta_ny: ', str(individual[2]) + ' gamma_u: ' + str(individual[3]) + ' fitness: ' + str(fitness)\n",
    "    \n",
    "    f = open(\"../Data_Labour/parameters_fitness.txt\",\"a\")\n",
    "    f.write(string + \"\\n\")\n",
    "    results.append({'fitness':fitness, 'individual':individual})\n",
    "\n",
    "    return fitness,\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-6fb38c73d2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlpg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-101-6fb38c73d2f5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     pop, log = algorithms.eaMuPlusLambda(pop, toolbox, mu = 10, lambda_ = 20, cxpb=0.5, mutpb=0.4, ngen=15, \n\u001b[0;32m---> 79\u001b[0;31m                                    stats=stats, halloffame=hof, verbose=True)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# Evaluate the individuals with an invalid fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#    License along with DEAP. If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "import array\n",
    "import random\n",
    "\n",
    "import numpy\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, typecode='b', fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "open(\"../Data_Labour/parameters_fitness.txt\",\"w+\")\n",
    "\n",
    "# parameters['a'] = [0.01, 0.03]\n",
    "# parameters['delta_u'] = [0.0065, 0.01]\n",
    "# parameters['delta_ny'] = [0.0055, 0.006, 0.0065]\n",
    "# parameters['gamma_u'] = [0.15, 0.16, 0.165]\n",
    "# parameters['timestep'] = [3.3]\n",
    "# parameters['gamma_ny'] = parameters['gamma_u']\n",
    "\n",
    "# Attribute generator\n",
    "# toolbox.register(\"attr\", random.uniform, 0, 0.2)\n",
    "\n",
    "\n",
    "\n",
    "# func_seq = [lambda:random.uniform(0.01, 0.2), lambda:random.uniform(0.005, 0.09), lambda:random.uniform(0.001, 0.05), lambda:random.uniform(0.05, 0.2)]\n",
    "\n",
    "# a: 0.022252957991699827 delta_u: 0.01075412432464562 delta_ny: 0.009035380457934611 gamma_u: 0.13015569282507672\n",
    "# a: 0.01927319683779494 delta_u: 0.017759426492261806 delta_ny: 0.009603112274559051 gamma_u: 0.1436019268182242\n",
    "# a: 0.019498541354135167 delta_u: 0.017156297087313012 delta_ny: 0.009231119344329925 gamma_u: 0.13942978729410904\n",
    "\n",
    "# def nvariate_seq(mu, sigma):\n",
    "#     abs(random.normalvariate(mu, sigma))\n",
    "\n",
    "func_seq = [lambda : abs(random.normalvariate(0.04, 0.02)), lambda : abs(random.normalvariate(0.018, 0.001)), lambda : abs(random.normalvariate(0.005, 0.001)), lambda : abs(random.normalvariate(0.16, 0.01))]\n",
    "\n",
    "# func_seq = [nvariate_seq(0.04, 0.02)]\n",
    "\n",
    "# a: 0.05 delta_u: 0.01 delta_ny: 0.005 gamma_u: 0.13\n",
    "# a: 0.02848946154491157 delta_u: 0.010664600228730777 delta_ny: 0.0023964714590789093 gamma_u: 0.1282955755725513\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual, func_seq, n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", eval_func)\n",
    "toolbox.register(\"mate\", tools.cxUniform, indpb = 0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu = 0.01, sigma = 0.01, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(64)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    pool = multiprocessing.Pool()\n",
    "    toolbox.register(\"map\", pool.map)\n",
    "\n",
    "    \n",
    "    pop = toolbox.population(n=40)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", numpy.mean)\n",
    "    stats.register(\"std\", numpy.std)\n",
    "    stats.register(\"min\", numpy.min)\n",
    "    stats.register(\"max\", numpy.max)\n",
    "    \n",
    "    pop, log = algorithms.eaMuPlusLambda(pop, toolbox, mu = 10, lambda_ = 20, cxpb=0.5, mutpb=0.4, ngen=15, \n",
    "                                   stats=stats, halloffame=hof, verbose=True)\n",
    "    \n",
    "    return pop, log, hof\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, lpg, hof = main()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}