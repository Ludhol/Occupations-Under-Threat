{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages (check which are required)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import datetime as dt\n",
    "import community\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "import importlib\n",
    "import ddom\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import cmocean as cmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from data_processing.ipynb\n",
    "sa_calibration_data = pd.read_csv('../Data_Labour/calibration_data.csv')\n",
    "employment_SSYK = pd.read_csv('../Data_Labour/occupational_employment.csv', sep = ',')\n",
    "SSYK_shock = pd.read_csv('../Data_Labour/occupation_shock.csv', sep = ',', index_col = 0)\n",
    "hours_data = pd.read_csv('../Data_Labour/hours_data.csv', sep = ',', index_col = 0)\n",
    "\n",
    "G = nx.read_graphml('../Data_Labour/Occ_mob_sweden.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation started at:  2020-05-18 03:18:49.069108\n",
      "simulation took: 0:00:24.926609\n",
      "Simulation started at:  2020-05-18 03:19:14.210565\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-a618ab05bb39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                        \u001b[0mtimestep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshock_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshock_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                         \u001b[0mavg_hours_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_hours_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                        t_0 = shock_period/2, complete_network = True, steady_state = True)\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mu_ss_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_ls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mvac_ss_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_ls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MSc_Thesis/Code Labour/ddom.py\u001b[0m in \u001b[0;36mdeterministic_simulation\u001b[0;34m(G, delta_u, delta_nu, gamma_u, gamma_nu, timestep, period, attributes, t_0, avg_hours_0, k, shock_period, long_term, complete_network, calibration, steady_state, empirical_data, a)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;31m# This is done via the expression arrived at by Taylor expansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 \u001b[0mnu_A_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnu_A_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MSc_Thesis/Code Labour/ddom.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;31m# This is done via the expression arrived at by Taylor expansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 \u001b[0mnu_A_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnu_A_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(ddom)\n",
    "employment = employment_SSYK[['ssyk3', '2016']]\n",
    "employment = {str(employment['ssyk3'].iloc[i]):employment['2016'].iloc[i] for i in range(len(employment))}\n",
    "node_names = G.nodes()\n",
    "\n",
    "# setup network\n",
    "employed = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "unemployed = {name:0 for name in node_names}\n",
    "vacancies = {name:0 for name in node_names}\n",
    "\n",
    "target_demand = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "of_data = SSYK_shock.to_dict()['Computerisation Probability']\n",
    "of_data = {str(code):prob for code, prob in of_data.items()}\n",
    "\n",
    "attributes = {'employed':employed, 'unemployed':unemployed, 'vacancies':vacancies,\n",
    "                'target_demand':target_demand, 'comp_prob':of_data}\n",
    "\n",
    "a = 0.035\n",
    "delta_u = 0.011\n",
    "delta_nu = 0.005\n",
    "gamma_u = 0.1\n",
    "gamma_nu = gamma_u\n",
    "timestep = 8\n",
    "\n",
    "period = 10.25\n",
    "k = 0.79\n",
    "avg_hours_0 = hours_data.loc[2016,'average_hours/year']\n",
    "\n",
    "u_ss_ls = []\n",
    "vac_ss_ls = []\n",
    "c_u_ss_ls = []\n",
    "c_vac_ss_ls = []\n",
    "for du in np.arange(0.005, 0.012, 0.002):\n",
    "    for dnu in np.arange(0.011, 0.004, -0.002):\n",
    "        G = nx.read_graphml('../Data_Labour/Occ_mob_sweden.graphml')\n",
    "        en_ls = ddom.deterministic_simulation(G, round(du,3), round(dnu,3), gamma_u, gamma_nu, \n",
    "                                       timestep, period, attributes, shock_period = shock_period, k = k, \n",
    "                                        avg_hours_0 = avg_hours_0, t_0 = shock_period/2, steady_state = True)\n",
    "        G = nx.read_graphml('../Data_Labour/Occ_mob_sweden.graphml')\n",
    "        c_ls = ddom.deterministic_simulation(G, round(du,3), round(dnu,3), gamma_u, gamma_nu, \n",
    "                                       timestep, period, attributes, shock_period = shock_period, k = k, \n",
    "                                        avg_hours_0 = avg_hours_0, \n",
    "                                       t_0 = shock_period/2, complete_network = True, steady_state = True)\n",
    "        u_ss_ls.append(en_ls[0])\n",
    "        vac_ss_ls.append(en_ls[1])\n",
    "        c_u_ss_ls.append(c_ls[0])\n",
    "        c_vac_ss_ls.append(c_ls[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"#62bc5a\", \"#bd77d7\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6,4))\n",
    "\n",
    "ax.grid(linewidth=2, color='#999999', alpha=0.4)\n",
    "ax.tick_params(axis='both', which='both', labelsize=13,\n",
    "                labelbottom=True, bottom=True, labelleft=True, left=True)\n",
    "ax.grid(linewidth=2, color='#999999', alpha=0.4)\n",
    "ax.tick_params(axis='both', which='both', labelsize=13,\n",
    "                labelbottom=True, bottom=True, labelleft=True, left=True)\n",
    "\n",
    "    \n",
    "ax.set_title(r'Steady states for varying $\\delta_u$ and $\\delta_\\nu$', fontsize = 16)\n",
    "\n",
    "ax.scatter(u_ss_ls, vac_ss_ls, c = cols[0], alpha = 0.7, ec = 'k')\n",
    "ax.scatter(c_u_ss_ls, c_vac_ss_ls, c = cols[0], alpha = 0.7, ec = 'k')\n",
    "ax.set_ylabel('Unemployment \\n change (%)', fontsize = 14)\n",
    "ax.set_xlabel('Computerisation Probability', fontsize = 14)\n",
    "\n",
    "plt.savefig('../Graphs/unemployment_occupation.pdf', dpi=425, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011\n",
      "0.009\n",
      "0.006999999999999999\n",
      "0.004999999999999999\n"
     ]
    }
   ],
   "source": [
    "for du in np.arange(0.011, 0.004, -0.002):\n",
    "    print(du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation started at:  2020-05-17 15:13:13.237321\n",
      "Simulation took:  0:24:45.537200\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ddom)\n",
    "employment = employment_SSYK[['ssyk3', '2016']]\n",
    "employment = {str(employment['ssyk3'].iloc[i]):employment['2016'].iloc[i] for i in range(len(employment))}\n",
    "node_names = G.nodes()\n",
    "\n",
    "# setup network\n",
    "employed = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "unemployed = {name:0 for name in node_names}\n",
    "vacancies = {name:0 for name in node_names}\n",
    "\n",
    "target_demand = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "of_data = SSYK_shock.to_dict()['Computerisation Probability']\n",
    "of_data = {str(code):prob for code, prob in of_data.items()}\n",
    "\n",
    "attributes = {'employed':employed, 'unemployed':unemployed, 'vacancies':vacancies,\n",
    "                'target_demand':target_demand, 'comp_prob':of_data}\n",
    "\n",
    "# Parameters short calibration\n",
    "#delta_u = 0.009\n",
    "#delta_nu = 0.002\n",
    "#gamma_u = 0.1\n",
    "#gamma_nu = gamma_u\n",
    "#timestep = 14\n",
    "\n",
    "# Paramters long calibration (currently running)\n",
    "a = 0.035\n",
    "delta_u = 0.011\n",
    "delta_nu = 0.005\n",
    "gamma_u = 0.1\n",
    "gamma_nu = gamma_u\n",
    "timestep = 8\n",
    "\n",
    "period = 10.25\n",
    "k = 0.79\n",
    "avg_hours_0 = hours_data.loc[2016,'average_hours/year']\n",
    "\n",
    "output = {}\n",
    "\n",
    "for shock_period in [30]:\n",
    "    output[str(shock_period)] = ddom.deterministic_simulation(G, delta_u, delta_nu, gamma_u, gamma_nu, \n",
    "                                       timestep, period, attributes, shock_period = shock_period, k = k, \n",
    "                                        avg_hours_0 = avg_hours_0, \n",
    "                                       t_0 = shock_period/2, complete_network = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period, out in output.items():\n",
    "    vac_data = pd.DataFrame(out['vacancy_data'])\n",
    "    u_data = pd.DataFrame(out['unemployment_data'])\n",
    "    e_data = pd.DataFrame(out['employment_data'])\n",
    "    td_data = pd.DataFrame(out['target_demand_data'])\n",
    "    td_data.to_csv('../Data_Labour/simulation_output/det_td_simulation_'+period+'.csv', sep = ',', index = False)\n",
    "    vac_data.to_csv('../Data_Labour/simulation_output/det_vac_simulation_'+period+'.csv', sep = ',', index = False)\n",
    "    e_data.to_csv('../Data_Labour/simulation_output/det_emp_simulation_'+period+'.csv', sep = ',', index = False)\n",
    "    u_data.to_csv('../Data_Labour/simulation_output/det_unemp_simulation_'+period+'.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period, out in output.items():\n",
    "    vac_data = pd.DataFrame(out['vacancy_data'])\n",
    "    u_data = pd.DataFrame(out['unemployment_data'])\n",
    "    e_data = pd.DataFrame(out['employment_data'])\n",
    "    td_data = pd.DataFrame(out['target_demand_data'])\n",
    "    td_data.to_csv('../Data_Labour/simulation_output/c_det_td_simulation_'+period+'.csv', sep = ',', index = False)\n",
    "    vac_data.to_csv('../Data_Labour/simulation_output/c_det_vac_simulation_'+period+'.csv', sep = ',', index = False)\n",
    "    e_data.to_csv('../Data_Labour/simulation_output/c_det_emp_simulation_'+period+'.csv', sep = ',', index = False)\n",
    "    u_data.to_csv('../Data_Labour/simulation_output/c_det_unemp_simulation_'+period+'.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation started at:  2020-05-17 15:44:47.711196\n",
      "Simulation completed 2020-05-17 20:44:41.966399\n",
      "Simulation took:  4:59:54.256317\n",
      "Simulation started at:  2020-05-17 20:44:42.438862\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-d58d94f34e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graphml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data_Labour/Occ_mob_sweden.graphml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     output_abm = ddom.simulation(G, delta_u, delta_nu, gamma_u, gamma_nu, timestep, \n\u001b[0;32m---> 50\u001b[0;31m                                  period, shock_period, k, avg_hours_0, t_0, attributes, complete_network = False)\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mvac_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_abm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vacancy_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mu_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_abm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unemployment_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MSc_Thesis/Code Labour/ddom.py\u001b[0m in \u001b[0;36msimulation\u001b[0;34m(G, delta_u, delta_nu, gamma_u, gamma_nu, timestep, period, shock_period, k, avg_hours_0, t_0, attributes, long_term, complete_network)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# Conduct the simulation steps:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# First, accept applications from previous timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mhandle_applications\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# Then, let the (unemployed) workers that were not accepted or did not apply last timestep, apply to vacancies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MSc_Thesis/Code Labour/ddom.py\u001b[0m in \u001b[0;36mhandle_applications\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# A random application is chosen (and removed from the list of applications)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0maccepted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;31m# Increase the amount of employed people in the occupation by the number of filled vacancies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0memp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moccupation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "employment = employment_SSYK[['ssyk3', '2016']]\n",
    "employment = {str(employment['ssyk3'].iloc[i]):employment['2016'].iloc[i] for i in range(len(employment))}\n",
    "node_names = G.nodes()\n",
    "\n",
    "importlib.reload(ddom)\n",
    "\n",
    "\n",
    "# setup network\n",
    "employed = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "unemployed = {name:0 for name in node_names}\n",
    "vacancies = {name:[] for name in node_names}\n",
    "\n",
    "target_demand = {str(name):e for name,e in employment.items() if str(name) in node_names}\n",
    "of_data = SSYK_shock.to_dict()['Computerisation Probability']\n",
    "of_data = {str(code):prob for code, prob in of_data.items()}\n",
    "\n",
    "attributes = {'employed':employed, 'unemployed':unemployed, 'vacancies':vacancies,\n",
    "                'target_demand':target_demand, 'comp_prob':of_data}\n",
    "\n",
    "# Parameters short calibration\n",
    "#delta_u = 0.009\n",
    "#delta_nu = 0.002\n",
    "#gamma_u = 0.1\n",
    "#gamma_nu = gamma_u\n",
    "#timestep = 14\n",
    "\n",
    "# Paramters long calibration (currently running)\n",
    "delta_u = 0.011\n",
    "delta_nu = 0.005\n",
    "gamma_u = 0.1\n",
    "gamma_nu = gamma_u\n",
    "timestep = 8\n",
    "\n",
    "# General parameters\n",
    "period = 10.25\n",
    "shock_period = 30\n",
    "k = 0.79\n",
    "avg_hours_0 = hours_data.loc[2016,'average_hours/year']\n",
    "t_0 = shock_period/2\n",
    "\n",
    "vac_datalist = []\n",
    "u_datalist = []\n",
    "e_datalist = []\n",
    "td_datalist = []\n",
    "lt_u_datalist = []\n",
    "\n",
    "for i in range(3,6):\n",
    "    G = nx.read_graphml('../Data_Labour/Occ_mob_sweden.graphml')\n",
    "    output_abm = ddom.simulation(G, delta_u, delta_nu, gamma_u, gamma_nu, timestep, \n",
    "                                 period, shock_period, k, avg_hours_0, t_0, attributes, complete_network = False)\n",
    "    vac_data = pd.DataFrame(output_abm['vacancy_data'])\n",
    "    u_data = pd.DataFrame(output_abm['unemployment_data'])\n",
    "    e_data = pd.DataFrame(output_abm['employment_data'])\n",
    "    td_data = pd.DataFrame(output_abm['target_demand_data'])\n",
    "    vac_datalist.append(vac_data)\n",
    "    u_datalist.append(u_data)\n",
    "    e_datalist.append(e_data)\n",
    "    td_datalist.append(td_data)\n",
    "    vac_data.to_csv('../Data_Labour/simulation_output/c_vac_simulation_'+str(i)+'.csv', sep = ',', index = False)\n",
    "    e_data.to_csv('../Data_Labour/simulation_output/c_emp_simulation_'+str(i)+'.csv', sep = ',', index = False)\n",
    "    u_data.to_csv('../Data_Labour/simulation_output/c_unemp_simulation_'+str(i)+'.csv', sep = ',', index = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitd863a529c1fa4d128753e3d722b9a701"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
