{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input and Processing\n",
    "This Jupyter Notebook contains code that takes the raw data files from Statistics Sweden and produces the files that are used in the analysis.\n",
    "\n",
    "## The data from Statistics Sweden:\n",
    "Occupational Transitions betweeen 2016 and 2017\n",
    "Quarterly Seasonally adjusted vacancy and employment data between 2004 and 2019\n",
    "Quarterly Seasonally and Calender adjusted unemployment data between 2004 and 2019\n",
    "Yearly Employment data distributed by SSYK occupational code between 2014 and 2018\n",
    "Yearly averages of total weekly hours worked between 2014 and 2018\n",
    "\n",
    "## Computerisation Probabilities from Frey & Osborne\n",
    "This data was developed for the american SOC (System for Occupational Classifications) and has to be translated to match Swedish data\n",
    "First the data is translated to ISCO using a key from https://ibs.org.pl/en/resources/occupation-classifications-crosswalks-from-onet-soc-to-isco/ which is based on work of David Autor and Daron Acemoglu: http://economics.mit.edu/faculty/dautor/data/acemoglu\n",
    "Then the data is translated using a key found on Statistics Sweden's website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import datetime as dt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import cmocean as cmo\n",
    "\n",
    "# Write files\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupational transitions and the Adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The occupations which only have one incoming edge (from themselves):\n",
      "['323', '622', '952']\n",
      "The occupations which only have one outgoing edge (to themselves):\n",
      "['323', '622']\n"
     ]
    }
   ],
   "source": [
    "# This is where the occupation transition data (as well as occupation code keys) is imported\n",
    "\n",
    "data = pd.read_csv('../Data_Labour/swedish_occupation_transitions.csv', sep = ';', index_col = 0)\n",
    "data.index.name = None\n",
    "data = data.drop(axis = 1, labels = 'Totalsumma')\n",
    "data = data.drop(axis = 1, index = 'Totalsumma')\n",
    "last = data.index[-1]\n",
    "data = data.rename(index={last: 'NULL'})\n",
    "\n",
    "# Drop Null and '***' columns\n",
    "data = data.iloc[0:148, 0:148]\n",
    "\n",
    "# ['31', '21', '11'] Are actually meant to be '031', '021' and '011'. \n",
    "# The 0 denotes that these are military occupations. \n",
    "# The data from Frey and Osborne do not cover military information which means that we cannot include \n",
    "# it in our analysis\n",
    "data.drop(labels = ['31', '21', '11'], axis = 0, inplace = True)\n",
    "data.drop(labels = ['31', '21', '11'], axis = 1, inplace = True)\n",
    "\n",
    "# This section calculates the adjacency matrix A from the raw data\n",
    "A = pd.DataFrame(np.zeros(data.shape), columns = data.columns, index = data.index)\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    total = 0\n",
    "    for t in range(data.shape[1]):\n",
    "        if math.isnan(data.iloc[i,t]) != True:\n",
    "            total += data.iloc[i,t]\n",
    "        else:\n",
    "            data.iloc[i, t] = 0\n",
    "\n",
    "    for j in range(data.shape[1]):\n",
    "        T = data.iloc[i,j]\n",
    "        A.iloc[i,j] = (T/total)\n",
    "\n",
    "A.index = A.index.map(str)\n",
    "A.columns = A.columns.map(str)\n",
    "G = nx.from_pandas_adjacency(A, create_using = nx.DiGraph)\n",
    "\n",
    "print('The occupations which only have one incoming edge (from themselves):')\n",
    "one_in_ls = [key for key, val in G.in_degree() if val == 1]\n",
    "print(one_in_ls)\n",
    "print('The occupations which only have one outgoing edge (to themselves):')\n",
    "one_out_ls = [key for key, val in G.out_degree() if val == 1]\n",
    "print(one_out_ls)\n",
    "\n",
    "# SSYK 323 and 622 only has selfloops and are not connected to the main component of the graph\n",
    "# SSYK 952 only has one incoming edge - and the target demand goes below 50 - which means that the \n",
    "# deterministic solution does not hold for it\n",
    "# As discussed in the thesis - these are removed\n",
    "data.drop(labels = ['323', '622', '952'], axis = 0, inplace = True)\n",
    "data.drop(labels = ['323', '622', '952'], axis = 1, inplace = True)\n",
    "A.drop(labels = ['323', '622', '952'], axis = 0, inplace = True)\n",
    "A.drop(labels = ['323', '622', '952'], axis = 1, inplace = True)\n",
    "\n",
    "G = nx.from_pandas_adjacency(A, create_using = nx.DiGraph)\n",
    "\n",
    "data.to_csv('../Data_Labour/Occupation_transitions.csv', sep = ',')\n",
    "nx.write_graphml(G, '../Data_Labour/Occ_mob_sweden.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frey & Osborne Computerisation Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# This is where the automation shock data from Frey and Osborne is \n",
    "# imported and processed between occupation classification systems\n",
    "\n",
    "frey_osborne = pd.read_csv('../Data_Labour/osborne_frey_data.csv', sep = ';', index_col = 0)\n",
    "\n",
    "SOC_shock = frey_osborne[['Probability', 'SOC code']]\n",
    "SOC_shock.columns = ['Computerisation Probability', 'soc10']\n",
    "\n",
    "for i in range(len(SOC_shock['soc10'])):\n",
    "    SOC_shock.iloc[i,1] = SOC_shock.iloc[i,1][0:2] + SOC_shock.iloc[i,1][3:7]\n",
    "    #SOC_shock.iloc[i,1] = SOC_shock.iloc[i,1]\n",
    "\n",
    "\n",
    "SOC_ISCO = pd.read_csv('../Data_Labour/soc10_isco08.csv', sep = ',')\n",
    "for i in range(len(SOC_ISCO['isco08'])):\n",
    "    SOC_ISCO.iloc[i,1] = str(SOC_ISCO.iloc[i,1])\n",
    "    SOC_ISCO.iloc[i,0] = str(SOC_ISCO.iloc[i,0])\n",
    "    # if len(SOC_ISCO.iloc[i,1]) == 3:\n",
    "    #     SOC_ISCO.iloc[i,1] = '0' + SOC_ISCO.iloc[i,1]\n",
    "\n",
    "ISCO_SSYK = pd.read_csv('../Data_Labour/nyckel_ssyk2012_isco-08.csv', sep = ';')\n",
    "ISCO_SSYK = ISCO_SSYK[['SSYK 2012 kod','ISCO-08 ']]\n",
    "ISCO_SSYK.columns = ['ssyk12', 'isco08']\n",
    "\n",
    "for i in range(len(ISCO_SSYK['isco08'])):\n",
    "    ISCO_SSYK.iloc[i,1] = str(ISCO_SSYK.iloc[i,1])\n",
    "    ISCO_SSYK.iloc[i,0] = str(ISCO_SSYK.iloc[i,0])\n",
    "\n",
    "\n",
    "# The file above contains many duplicates\n",
    "ISCO_SSYK.drop_duplicates(inplace=True)\n",
    "\n",
    "# Below transfers SOC_shock to SSYK_shock\n",
    "ISCO_shock = pd.merge(SOC_shock, SOC_ISCO, on = 'soc10')\n",
    "\n",
    "SSYK_shock = pd.merge(ISCO_shock, ISCO_SSYK, on = 'isco08')\n",
    "\n",
    "\n",
    "# The codes are 4 level need to be 3 level. Only need to change final table (SSYK_shock)\n",
    "SSYK_shock['ssyk3'] =  [str(code[0:3]) for code in SSYK_shock['ssyk12']]\n",
    "\n",
    "SSYK3_shock = SSYK_shock[['Computerisation Probability', 'ssyk3']]\n",
    "\n",
    "SSYK3 = list(SSYK3_shock['ssyk3'])\n",
    "\n",
    "SSYK3_shock = SSYK3_shock.groupby(['ssyk3']).mean()\n",
    "#SSYK3_shock['ssyk3'] =  [str(code) for code in SSYK3_shock['ssyk3']]\n",
    "\n",
    "G = nx.from_pandas_adjacency(A, create_using = nx.DiGraph)\n",
    "SSYK3_fromnw = list(G.nodes)\n",
    "SSYK3_fromnw = [str(node) for node in SSYK3_fromnw]\n",
    "\n",
    "SSYK3_shock.to_csv('../Data_Labour/occupation_shock.csv', sep = ',')\n",
    "\n",
    "# Problem is that certain SOC codes in osborne frey have been abbreviated with 0s. \n",
    "# Which makes the matching miss a few rows\n",
    "# This problem can be fixed\n",
    "\n",
    "# SOC codes that are not found in the SOC-ISCO translation file\n",
    "# print(set(SOC_shock['soc10'])-set(SOC_ISCO['soc10']))\n",
    "# {'292037', '292055', '499799', '291060', '394831', '319799', '292799', '251000', '253999', \n",
    "# '151179', '474799', '131078', '452090', '299799', '151150', '151799', '519399', '291111'}\n",
    "\n",
    "# Focus on '251000', '151150', '291060'\n",
    "# 291060 solves 221 because 291060 doesnt exist in soc_isco\n",
    "# 291141, 291151, 291171, 291161 <- 222\n",
    "# 29-1111 is not used anymore, 29-1141 should be used instead: https://www.onetonline.org/find/quick?s=29-1111\n",
    "\n",
    "# 231 ssyk: soc_isco översätter till isco 2310 som inte existerar i isco_ssyk nykeln där det istället är 231X. \n",
    "\n",
    "# 251000: Post-secondary teachers is translated as 2310 SSYK\n",
    "\n",
    "# SSYK codes not found in ISCO-SSYK translation file\n",
    "# print(list(set(SSYK3_fromnw) - set(SSYK3)))\n",
    "# ['221', '21', '11', '222', '231', '31']\n",
    "# ['21', '11', '31'] are military occupations and we do not have computersiation probabilities for these\n",
    "\n",
    "# focus on ['221', '222', '231']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupational employment distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSYK_labels = pd.read_csv('../Data_Labour/Ssyk-2012-koder.csv', sep = ';').astype(str)\n",
    "\n",
    "SSYK3_data = SSYK3_shock.merge(SSYK_labels, how = 'left', on = 'ssyk3')\n",
    "\n",
    "employment_SSYK = pd.read_csv('../Data_Labour/employment_SSYK.csv', sep = ',').astype(str)\n",
    "employment_SSYK.rename(columns = {'Yrke (SSYK 2012)':'ssyk3'}, inplace = True)\n",
    "employment_SSYK.to_csv('../Data_Labour/occupational_employment.csv', sep = ',')\n",
    "\n",
    "occupational_data = SSYK3_data.merge(employment_SSYK, on = 'ssyk3')\n",
    "occupational_data['Computerisation Probability'] = [round(comp, 5) for comp in \n",
    "                                                    occupational_data['Computerisation Probability']]\n",
    "occupational_data.index = occupational_data.ssyk3\n",
    "occupational_data.drop(columns = ['ssyk3'], inplace = True)\n",
    "\n",
    "# SSYK code and years as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computerisation Probability                              0.083\n",
       "swedish                             Restaurang- och kökschefer\n",
       "english                        Restaurant and kitchen managers\n",
       "2014                                                      6461\n",
       "2015                                                      6936\n",
       "2016                                                      7460\n",
       "2017                                                      7738\n",
       "2018                                                      7811\n",
       "Name: 172, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell allows you to find data on a given occupation by its SSYK code\n",
    "occupational_data.loc['172']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dict_keyiterator object at 0x12538def0>\n"
     ]
    }
   ],
   "source": [
    "nx.neighbors(G,'138')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting together all occupational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computerisation Probability</th>\n",
       "      <th>swedish</th>\n",
       "      <th>english</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>post-shock demand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssyk3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.00390</td>\n",
       "      <td>Hotell- och konferenschefer</td>\n",
       "      <td>Hotel and conference managers</td>\n",
       "      <td>1251</td>\n",
       "      <td>1290</td>\n",
       "      <td>1471</td>\n",
       "      <td>1553</td>\n",
       "      <td>1512</td>\n",
       "      <td>2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.00420</td>\n",
       "      <td>Läkare</td>\n",
       "      <td>Medical Doctors</td>\n",
       "      <td>37242</td>\n",
       "      <td>37474</td>\n",
       "      <td>38873</td>\n",
       "      <td>39826</td>\n",
       "      <td>41314</td>\n",
       "      <td>72700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.00700</td>\n",
       "      <td>Psykologer och psykoterapeuter</td>\n",
       "      <td>Psychologists and psychotherapists</td>\n",
       "      <td>7972</td>\n",
       "      <td>8044</td>\n",
       "      <td>8588</td>\n",
       "      <td>8917</td>\n",
       "      <td>9165</td>\n",
       "      <td>16082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.00700</td>\n",
       "      <td>Chefer inom socialt och kurativt arbete</td>\n",
       "      <td>Managers of social and curative work</td>\n",
       "      <td>3783</td>\n",
       "      <td>4071</td>\n",
       "      <td>4812</td>\n",
       "      <td>5127</td>\n",
       "      <td>5114</td>\n",
       "      <td>8973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.00730</td>\n",
       "      <td>Chefer inom hälso- och sjukvård</td>\n",
       "      <td>Healthcare managers''</td>\n",
       "      <td>10634</td>\n",
       "      <td>11005</td>\n",
       "      <td>11718</td>\n",
       "      <td>11933</td>\n",
       "      <td>12632</td>\n",
       "      <td>22159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0.88625</td>\n",
       "      <td>Snabbmatspersonal, köks- och restaurangbiträden m.fl.</td>\n",
       "      <td>Fast food staff, kitchen and restaurant assistants</td>\n",
       "      <td>68912</td>\n",
       "      <td>77998</td>\n",
       "      <td>77340</td>\n",
       "      <td>79024</td>\n",
       "      <td>79038</td>\n",
       "      <td>15887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>0.91571</td>\n",
       "      <td>Montörer</td>\n",
       "      <td>Installers</td>\n",
       "      <td>53785</td>\n",
       "      <td>52317</td>\n",
       "      <td>49282</td>\n",
       "      <td>56305</td>\n",
       "      <td>61879</td>\n",
       "      <td>9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0.92000</td>\n",
       "      <td>Torg- och marknadsförsäljare</td>\n",
       "      <td>Square and market vendors</td>\n",
       "      <td>121</td>\n",
       "      <td>142</td>\n",
       "      <td>149</td>\n",
       "      <td>157</td>\n",
       "      <td>190</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.93400</td>\n",
       "      <td>Kassapersonal m.fl.</td>\n",
       "      <td>Cashiers and others</td>\n",
       "      <td>13567</td>\n",
       "      <td>14887</td>\n",
       "      <td>15101</td>\n",
       "      <td>15316</td>\n",
       "      <td>13400</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.95750</td>\n",
       "      <td>Biblioteks- och arkivassistenter m.fl.</td>\n",
       "      <td>Library and Archive Assistants</td>\n",
       "      <td>3408</td>\n",
       "      <td>3419</td>\n",
       "      <td>3463</td>\n",
       "      <td>3321</td>\n",
       "      <td>3320</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Computerisation Probability  \\\n",
       "ssyk3                                \n",
       "171                        0.00390   \n",
       "221                        0.00420   \n",
       "224                        0.00700   \n",
       "152                        0.00700   \n",
       "151                        0.00730   \n",
       "...                            ...   \n",
       "941                        0.88625   \n",
       "821                        0.91571   \n",
       "952                        0.92000   \n",
       "523                        0.93400   \n",
       "441                        0.95750   \n",
       "\n",
       "                                                     swedish  \\\n",
       "ssyk3                                                          \n",
       "171                              Hotell- och konferenschefer   \n",
       "221                                                   Läkare   \n",
       "224                           Psykologer och psykoterapeuter   \n",
       "152                  Chefer inom socialt och kurativt arbete   \n",
       "151                          Chefer inom hälso- och sjukvård   \n",
       "...                                                      ...   \n",
       "941    Snabbmatspersonal, köks- och restaurangbiträden m.fl.   \n",
       "821                                                 Montörer   \n",
       "952                             Torg- och marknadsförsäljare   \n",
       "523                                      Kassapersonal m.fl.   \n",
       "441                   Biblioteks- och arkivassistenter m.fl.   \n",
       "\n",
       "                                                  english   2014   2015  \\\n",
       "ssyk3                                                                     \n",
       "171                         Hotel and conference managers   1251   1290   \n",
       "221                                       Medical Doctors  37242  37474   \n",
       "224                    Psychologists and psychotherapists   7972   8044   \n",
       "152                  Managers of social and curative work   3783   4071   \n",
       "151                                 Healthcare managers''  10634  11005   \n",
       "...                                                   ...    ...    ...   \n",
       "941    Fast food staff, kitchen and restaurant assistants  68912  77998   \n",
       "821                                            Installers  53785  52317   \n",
       "952                             Square and market vendors    121    142   \n",
       "523                                   Cashiers and others  13567  14887   \n",
       "441                        Library and Archive Assistants   3408   3419   \n",
       "\n",
       "        2016   2017   2018  post-shock demand  \n",
       "ssyk3                                          \n",
       "171     1471   1553   1512               2661  \n",
       "221    38873  39826  41314              72700  \n",
       "224     8588   8917   9165              16082  \n",
       "152     4812   5127   5114               8973  \n",
       "151    11718  11933  12632              22159  \n",
       "...      ...    ...    ...                ...  \n",
       "941    77340  79024  79038              15887  \n",
       "821    49282  56305  61879               9216  \n",
       "952      149    157    190                 26  \n",
       "523    15101  15316  13400               1562  \n",
       "441     3463   3321   3320                249  \n",
       "\n",
       "[145 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data used to calculate the post shock demand\n",
    "comp_prob = occupational_data['Computerisation Probability'].to_dict()\n",
    "average_hours_worked_0 = pd.read_csv('../Data_Labour/hours_data.csv', sep = ',', index_col = 0)\n",
    "average_hours_worked_0 = average_hours_worked_0.loc[2018,'average_hours/year']\n",
    "\n",
    "employed = occupational_data['2018'].to_dict()\n",
    "L = sum([int(val) for val in employed.values()])\n",
    "\n",
    "final_hours_worked = {occ : average_hours_worked_0*int(employed[occ])*(1-prob) for \n",
    "                      occ, prob in comp_prob.items()}\n",
    "final_average_hours_worked = sum(final_hours_worked.values())/L\n",
    "occupational_data['post-shock demand'] = [int(hours/final_average_hours_worked) for \n",
    "                                          hours in final_hours_worked.values()]\n",
    "occupational_data.to_csv('../Data_Labour/occupational_data.csv', sep = ',')\n",
    "pd.options.display.max_colwidth = 100\n",
    "occupational_data.sort_values(by = 'Computerisation Probability', axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupational_data.sort_values(by = 'Computerisation Probability', axis = 0).to_latex('../Tables/occupation_data.txt',\n",
    "                           columns = ['english', 'Computerisation Probability', '2014', \n",
    "                                      '2018', 'post-shock demand'],\n",
    "                          header = ['Description', 'Computerisation Probability', \n",
    "                                    'Employment 2014', 'Employment 2018', 'Post-shock demand'],\n",
    "                          bold_rows = True,\n",
    "                          label = 'tab:occ_res',\n",
    "                          longtable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deviations from potential GDP from Konjunktur Institutet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_gap = pd.read_csv('../Data_Labour/bnp-gap.csv', sep = ';')\n",
    "gdp_gap['Qtr'] = pd.to_datetime(gdp_gap.date).dt.quarter\n",
    "gdp_gap['date'] = [gdp_gap['date'].iloc[i][0:4] + 'Q' + str(gdp_gap['Qtr'].iloc[i]) for \n",
    "                   i in range(len(gdp_gap['date']))]\n",
    "gdp_gap['recession'] = [1 if gap <= 0 else 0 for gap in list(gdp_gap['BNP-gap'])]\n",
    "gap_offset = zip(gdp_gap['BNP-gap'].iloc[1:],gdp_gap['BNP-gap'].iloc[:-1])\n",
    "change_ls = [(gap_t1 - gap_t0)/gap_t0 for gap_t1, gap_t0 in gap_offset]\n",
    "change_ls.insert(0,float('NaN'))\n",
    "gdp_gap['gap_change'] = change_ls\n",
    "gdp_gap.rename(columns = {'BNP-gap': 'gdp_gap'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration data from Statistics Sweden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# New calibration data - seasonally adjusted\n",
    "employment_sa = pd.read_csv('../Data_Labour/employment_quarterly.csv', sep = ';')\n",
    "employment_sa['date'] = [str(2000 + employment_sa['year'].iloc[i])+'Q'+str(employment_sa['quarter'].iloc[i]) \n",
    "                         for i in range(len(employment_sa))]\n",
    "employment_sa = employment_sa[['date', 'e_sa', 'e_trend']]\n",
    "employment_sa['e_sa'] = [int(float(string.replace(',','.'))*1000) for string in employment_sa['e_sa']]\n",
    "employment_sa['e_trend'] = [int(float(string.replace(',','.'))*1000) for string in employment_sa['e_trend']]\n",
    "\n",
    "\n",
    "unemployment_all = pd.read_csv('../Data_Labour/unemployment_quarterly.csv', sep = ';')\n",
    "unemployment_all['date'] = [str(2000 + unemployment_all['year'].iloc[i])+'Q'+\n",
    "                            str(unemployment_all['quarter'].iloc[i]) for i in range(len(unemployment_all))]\n",
    "unemployment_sa = unemployment_all[['date', 'u_sa', 'u_trend']]\n",
    "\n",
    "unemployment_sa['u_sa'] = [float(string.replace(',','.')) for string in unemployment_sa['u_sa']]\n",
    "unemployment_sa['u_trend'] = [float(string.replace(',','.')) for string in unemployment_sa['u_trend']]\n",
    "\n",
    "vac_rate_all = pd.read_csv('../Data_Labour/Vacancy Data/sa_2004-2019.csv', sep = ';')\n",
    "\n",
    "sa_calibration_data = pd.merge(unemployment_sa, vac_rate_all[['date', 'sa_vac', 'na_vac']], on ='date')\n",
    "sa_calibration_data = pd.merge(sa_calibration_data, employment_sa, on = 'date')\n",
    "sa_calibration_data = pd.merge(sa_calibration_data, gdp_gap[['date', 'recession', 'gap_change']], on = 'date')\n",
    "\n",
    "sa_calibration_data['sa_vac_rate'] = sa_calibration_data['sa_vac']*100/(sa_calibration_data['e_trend']\n",
    "                                                                        +sa_calibration_data['sa_vac'])\n",
    "sa_calibration_data['year'] = [date[:4] for date in sa_calibration_data['date']]\n",
    "\n",
    "sa_calibration_data['workforce'] = sa_calibration_data['e_trend']/(1-sa_calibration_data['u_trend']/100)\n",
    "\n",
    "sa_calibration_data.to_csv('../Data_Labour/calibration_data.csv', sep = ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_calibration_data[['u_trend', 'sa_vac_rate']].describe().to_latex('../Tables/beveridge_data.txt',\n",
    "                          header = ['Unemployment rate', 'Vacancy rate'],\n",
    "                          bold_rows = True,\n",
    "                          label = 'tab:bev_dat',\n",
    "                          longtable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hours worked data (from Statistics Sweden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_worked = pd.read_csv('../Data_Labour/hours_worked_sa.csv', sep =',')\n",
    "hours_worked.drop(labels = ['ekonomisk indikator'], axis = 1, inplace = True)\n",
    "hours_worked = hours_worked.transpose()\n",
    "hours_worked.columns = ['hours/week']\n",
    "hours_worked['hours/week'] = hours_worked['hours/week']*1000\n",
    "hours_worked['year'] = [date[:4] for date in hours_worked.index]\n",
    "yearly_hours_worked = hours_worked.groupby(['year']).mean()\n",
    "\n",
    "yearly_employment = sa_calibration_data[['year','e_trend']].groupby(['year']).mean()\n",
    "yearly_hours_employment = pd.merge(yearly_employment, yearly_hours_worked, on = 'year')\n",
    "yearly_hours_employment['average_hours/week'] = (yearly_hours_employment['hours/week']/\n",
    "                                                 yearly_hours_employment['e_trend'])\n",
    "yearly_hours_employment['average_hours/year'] = yearly_hours_employment['average_hours/week']*52\n",
    "\n",
    "yearly_hours_employment.to_csv('../Data_Labour/hours_data.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the simulated data\n",
    "vac_data = pd.read_csv('../Data_Labour/vac_simulation.csv', sep = ',')\n",
    "emp_data = pd.read_csv('../Data_Labour/emp_simulation.csv', sep = ',')\n",
    "unemp_data = pd.read_csv('../Data_Labour/unemp_simulation.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitd863a529c1fa4d128753e3d722b9a701"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
